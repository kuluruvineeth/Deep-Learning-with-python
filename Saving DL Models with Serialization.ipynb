{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "frank-generation",
   "metadata": {},
   "source": [
    "# Saving DL Models\n",
    "## Keras separates the concerns of saving our model architecture and saving our model weights.\n",
    "* Model weights are saved to **HDF5** format.This is a grid format that is ideal for storing multi-dimensional arrays of numbers.\n",
    "* The model structure can be described and saved using two different formats: **JSON** and **YAML**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fabulous-confidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: h5py in /home/kuluruvineeth/.local/lib/python3.7/site-packages (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /home/kuluruvineeth/.local/lib/python3.7/site-packages (from h5py) (1.19.5)\n",
      "Requirement already satisfied: six in /home/kuluruvineeth/.local/lib/python3.7/site-packages (from h5py) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# HDF5(Hierarchical Data Format)\n",
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-advocacy",
   "metadata": {},
   "source": [
    "## 1. Saving our Neural Network Model to JSON\n",
    "* JSON is a simple file format for describing data hierarchically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "built-shame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 78.78%\n",
      "Saved model to disk\n",
      "Loaded model from disk\n",
      "accuracy: 78.78%\n"
     ]
    }
   ],
   "source": [
    "# MLP for pima indians dataset serialize to JSON and HDF5\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = np.loadtxt('pima-indians-diabetes.data.csv',delimiter=\",\")\n",
    "# split into input(X) and output(Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "model = Sequential()\n",
    "# create model\n",
    "model.add(Dense(12,input_dim=8,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X,Y,epochs=150,batch_size=10,verbose=0)\n",
    "\n",
    "# evaluate model\n",
    "scores = model.evaluate(X,Y,verbose=0)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1],scores[1]*100))\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "\n",
    "# later.....\n",
    "\n",
    "# load json and create model\n",
    "json_file = open(\"model.json\",\"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X,Y,verbose=0)\n",
    "print(\"%s: %.2f%%\" %(loaded_model.metrics_names[1],score[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-policy",
   "metadata": {},
   "source": [
    "## 2. Saving our neural network model to YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "authorized-reproduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 76.17%\n",
      "Saved model to disk\n",
      "Loaded model from disk\n",
      "accuracy: 76.17%\n"
     ]
    }
   ],
   "source": [
    "# MLP for pima indians dataset serialize to JSON and HDF5\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = np.loadtxt('pima-indians-diabetes.data.csv',delimiter=\",\")\n",
    "# split into input(X) and output(Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "model = Sequential()\n",
    "# create model\n",
    "model.add(Dense(12,input_dim=8,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X,Y,epochs=150,batch_size=10,verbose=0)\n",
    "\n",
    "# evaluate model\n",
    "scores = model.evaluate(X,Y,verbose=0)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1],scores[1]*100))\n",
    "\n",
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model.yaml\",\"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "\n",
    "# later.....\n",
    "\n",
    "# load json and create model\n",
    "yaml_file = open(\"model.yaml\",\"r\")\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X,Y,verbose=0)\n",
    "print(\"%s: %.2f%%\" %(loaded_model.metrics_names[1],score[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-processing",
   "metadata": {},
   "source": [
    "# Summary\n",
    "* Discovered Saving and Loading models is an important capability for transplanting a deep learning model from research and development to operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
